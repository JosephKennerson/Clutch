<<<<<<< HEAD
[2015-10-15 00:00:11,460][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:00:11,461][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:00:41,459][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:01:11,464][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:01:11,464][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:01:41,466][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:02:11,469][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:02:11,469][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:02:41,472][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:03:11,475][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:03:11,475][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:03:41,479][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:04:11,479][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:04:11,479][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:04:41,484][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:05:11,487][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:05:11,488][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:05:41,489][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:06:11,490][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:06:11,490][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:06:41,490][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:07:11,489][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:07:11,489][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:07:41,490][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:08:11,491][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:08:11,491][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:08:41,496][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:09:11,497][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:09:11,497][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:09:41,500][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:10:11,501][WARN ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark [90%] exceeded on [P-HVaJV0QC-QTLVeApLBWw][Diamond Lil] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:10:11,501][INFO ][cluster.routing.allocation.decider] [Diamond Lil] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:10:37,895][INFO ][node                     ] [Diamond Lil] stopping ...
[2015-10-15 00:10:37,912][INFO ][node                     ] [Diamond Lil] stopped
[2015-10-15 00:10:37,912][INFO ][node                     ] [Diamond Lil] closing ...
[2015-10-15 00:10:37,916][INFO ][node                     ] [Diamond Lil] closed
[2015-10-15 00:10:52,225][INFO ][node                     ] [Scimitar] version[1.7.1], pid[64222], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-15 00:10:52,226][INFO ][node                     ] [Scimitar] initializing ...
[2015-10-15 00:10:52,293][INFO ][plugins                  ] [Scimitar] loaded [], sites []
[2015-10-15 00:10:52,327][INFO ][env                      ] [Scimitar] using [1] data paths, mounts [[/ (/dev/disk0s2)]], net usable_space [25.3gb], net total_space [352.9gb], types [hfs]
[2015-10-15 00:10:54,277][INFO ][node                     ] [Scimitar] initialized
[2015-10-15 00:10:54,277][INFO ][node                     ] [Scimitar] starting ...
[2015-10-15 00:10:54,340][INFO ][transport                ] [Scimitar] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.8:9300]}
[2015-10-15 00:10:54,358][INFO ][discovery                ] [Scimitar] elasticsearch/e3fw3_EjRvum9iWV9fTcAw
[2015-10-15 00:10:58,136][INFO ][cluster.service          ] [Scimitar] new_master [Scimitar][e3fw3_EjRvum9iWV9fTcAw][Beepo-Retina.local][inet[/192.168.1.8:9300]], reason: zen-disco-join (elected_as_master)
[2015-10-15 00:10:58,167][INFO ][http                     ] [Scimitar] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.8:9200]}
[2015-10-15 00:10:58,168][INFO ][node                     ] [Scimitar] started
[2015-10-15 00:10:58,193][INFO ][gateway                  ] [Scimitar] recovered [2] indices into cluster_state
[2015-10-15 00:11:28,147][WARN ][cluster.routing.allocation.decider] [Scimitar] high disk watermark [90%] exceeded on [e3fw3_EjRvum9iWV9fTcAw][Scimitar] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:11:28,147][INFO ][cluster.routing.allocation.decider] [Scimitar] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:11:58,144][WARN ][cluster.routing.allocation.decider] [Scimitar] high disk watermark [90%] exceeded on [e3fw3_EjRvum9iWV9fTcAw][Scimitar] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:12:28,147][WARN ][cluster.routing.allocation.decider] [Scimitar] high disk watermark [90%] exceeded on [e3fw3_EjRvum9iWV9fTcAw][Scimitar] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:12:28,147][INFO ][cluster.routing.allocation.decider] [Scimitar] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:12:50,771][DEBUG][action.index             ] [Scimitar] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-10-15 00:12:58,151][WARN ][cluster.routing.allocation.decider] [Scimitar] high disk watermark [90%] exceeded on [e3fw3_EjRvum9iWV9fTcAw][Scimitar] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:13:28,155][WARN ][cluster.routing.allocation.decider] [Scimitar] high disk watermark [90%] exceeded on [e3fw3_EjRvum9iWV9fTcAw][Scimitar] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:13:28,156][INFO ][cluster.routing.allocation.decider] [Scimitar] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:13:36,272][INFO ][node                     ] [Scimitar] stopping ...
[2015-10-15 00:13:36,284][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.elasticsearch.common.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.elasticsearch.common.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.elasticsearch.common.netty.channel.Channels.write(Channels.java:725)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:195)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase.finishAsFailed(TransportShardReplicationOperationAction.java:536)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase$3.onClusterServiceClose(TransportShardReplicationOperationAction.java:509)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:217)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:174)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:105)
	at org.elasticsearch.node.internal.InternalNode.stop(InternalNode.java:310)
	at org.elasticsearch.node.internal.InternalNode.close(InternalNode.java:334)
	at org.elasticsearch.bootstrap.Bootstrap$1.run(Bootstrap.java:82)
[2015-10-15 00:13:36,294][INFO ][node                     ] [Scimitar] stopped
[2015-10-15 00:13:36,294][INFO ][node                     ] [Scimitar] closing ...
[2015-10-15 00:13:36,298][INFO ][node                     ] [Scimitar] closed
[2015-10-15 00:14:30,277][INFO ][node                     ] [Justin Hammer] version[1.7.1], pid[64862], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-15 00:14:30,278][INFO ][node                     ] [Justin Hammer] initializing ...
[2015-10-15 00:14:30,343][INFO ][plugins                  ] [Justin Hammer] loaded [], sites []
[2015-10-15 00:14:30,377][INFO ][env                      ] [Justin Hammer] using [1] data paths, mounts [[/ (/dev/disk0s2)]], net usable_space [25.3gb], net total_space [352.9gb], types [hfs]
[2015-10-15 00:14:32,326][INFO ][node                     ] [Justin Hammer] initialized
[2015-10-15 00:14:32,327][INFO ][node                     ] [Justin Hammer] starting ...
[2015-10-15 00:14:32,388][INFO ][transport                ] [Justin Hammer] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.8:9300]}
[2015-10-15 00:14:32,404][INFO ][discovery                ] [Justin Hammer] elasticsearch/3StrIZ3CQbm8qH4vW5aBLQ
[2015-10-15 00:14:36,183][INFO ][cluster.service          ] [Justin Hammer] new_master [Justin Hammer][3StrIZ3CQbm8qH4vW5aBLQ][Beepo-Retina.local][inet[/192.168.1.8:9300]], reason: zen-disco-join (elected_as_master)
[2015-10-15 00:14:36,216][INFO ][http                     ] [Justin Hammer] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.8:9200]}
[2015-10-15 00:14:36,217][INFO ][node                     ] [Justin Hammer] started
[2015-10-15 00:14:36,238][INFO ][gateway                  ] [Justin Hammer] recovered [2] indices into cluster_state
[2015-10-15 00:15:06,196][WARN ][cluster.routing.allocation.decider] [Justin Hammer] high disk watermark [90%] exceeded on [3StrIZ3CQbm8qH4vW5aBLQ][Justin Hammer] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:15:06,196][INFO ][cluster.routing.allocation.decider] [Justin Hammer] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:15:36,191][WARN ][cluster.routing.allocation.decider] [Justin Hammer] high disk watermark [90%] exceeded on [3StrIZ3CQbm8qH4vW5aBLQ][Justin Hammer] free: 25.2gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:15:38,854][DEBUG][action.index             ] [Justin Hammer] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-10-15 00:16:06,196][WARN ][cluster.routing.allocation.decider] [Justin Hammer] high disk watermark [90%] exceeded on [3StrIZ3CQbm8qH4vW5aBLQ][Justin Hammer] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:16:06,196][INFO ][cluster.routing.allocation.decider] [Justin Hammer] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:16:26,266][INFO ][node                     ] [Justin Hammer] stopping ...
[2015-10-15 00:16:26,278][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.elasticsearch.common.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.elasticsearch.common.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.elasticsearch.common.netty.channel.Channels.write(Channels.java:725)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:195)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase.finishAsFailed(TransportShardReplicationOperationAction.java:536)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase$3.onClusterServiceClose(TransportShardReplicationOperationAction.java:509)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:217)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:174)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:105)
	at org.elasticsearch.node.internal.InternalNode.stop(InternalNode.java:310)
	at org.elasticsearch.node.internal.InternalNode.close(InternalNode.java:334)
	at org.elasticsearch.bootstrap.Bootstrap$1.run(Bootstrap.java:82)
[2015-10-15 00:16:26,287][INFO ][node                     ] [Justin Hammer] stopped
[2015-10-15 00:16:26,288][INFO ][node                     ] [Justin Hammer] closing ...
[2015-10-15 00:16:26,292][INFO ][node                     ] [Justin Hammer] closed
[2015-10-15 00:52:12,116][INFO ][node                     ] [Bedlam] version[1.7.1], pid[1538], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-15 00:52:12,116][INFO ][node                     ] [Bedlam] initializing ...
[2015-10-15 00:52:12,235][INFO ][plugins                  ] [Bedlam] loaded [], sites []
[2015-10-15 00:52:12,293][INFO ][env                      ] [Bedlam] using [1] data paths, mounts [[/ (/dev/disk0s2)]], net usable_space [25.4gb], net total_space [352.9gb], types [hfs]
[2015-10-15 00:52:16,792][INFO ][node                     ] [Bedlam] initialized
[2015-10-15 00:52:16,793][INFO ][node                     ] [Bedlam] starting ...
[2015-10-15 00:52:17,239][INFO ][transport                ] [Bedlam] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.8:9300]}
[2015-10-15 00:52:17,277][INFO ][discovery                ] [Bedlam] elasticsearch/V_X2kzZmRbejXbcvdoPnTg
[2015-10-15 00:52:21,062][INFO ][cluster.service          ] [Bedlam] new_master [Bedlam][V_X2kzZmRbejXbcvdoPnTg][Beepo-Retina.local][inet[/192.168.1.8:9300]], reason: zen-disco-join (elected_as_master)
[2015-10-15 00:52:21,084][INFO ][http                     ] [Bedlam] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.8:9200]}
[2015-10-15 00:52:21,085][INFO ][node                     ] [Bedlam] started
[2015-10-15 00:52:21,122][INFO ][gateway                  ] [Bedlam] recovered [2] indices into cluster_state
[2015-10-15 00:52:51,074][WARN ][cluster.routing.allocation.decider] [Bedlam] high disk watermark [90%] exceeded on [V_X2kzZmRbejXbcvdoPnTg][Bedlam] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:52:51,074][INFO ][cluster.routing.allocation.decider] [Bedlam] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:53:21,072][WARN ][cluster.routing.allocation.decider] [Bedlam] high disk watermark [90%] exceeded on [V_X2kzZmRbejXbcvdoPnTg][Bedlam] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:53:51,074][WARN ][cluster.routing.allocation.decider] [Bedlam] high disk watermark [90%] exceeded on [V_X2kzZmRbejXbcvdoPnTg][Bedlam] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:53:51,074][INFO ][cluster.routing.allocation.decider] [Bedlam] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 00:54:21,079][WARN ][cluster.routing.allocation.decider] [Bedlam] high disk watermark [90%] exceeded on [V_X2kzZmRbejXbcvdoPnTg][Bedlam] free: 25.3gb[7.1%], shards will be relocated away from this node
[2015-10-15 00:54:40,336][INFO ][node                     ] [Bedlam] stopping ...
[2015-10-15 00:54:40,360][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.elasticsearch.common.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.elasticsearch.common.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.elasticsearch.common.netty.channel.Channels.write(Channels.java:725)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:195)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase.finishAsFailed(TransportShardReplicationOperationAction.java:536)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase$3.onClusterServiceClose(TransportShardReplicationOperationAction.java:509)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:217)
	at org.elasticsearch.cluster.service.InternalClusterService.doStop(InternalClusterService.java:174)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.stop(AbstractLifecycleComponent.java:105)
	at org.elasticsearch.node.internal.InternalNode.stop(InternalNode.java:310)
	at org.elasticsearch.node.internal.InternalNode.close(InternalNode.java:334)
	at org.elasticsearch.bootstrap.Bootstrap$1.run(Bootstrap.java:82)
[2015-10-15 00:54:40,374][INFO ][node                     ] [Bedlam] stopped
[2015-10-15 00:54:40,374][INFO ][node                     ] [Bedlam] closing ...
[2015-10-15 00:54:40,380][INFO ][node                     ] [Bedlam] closed
=======

[2015-10-14 14:16:27,431][INFO ][cluster.service          ] [Raza] added {[David Cannon][w2wuzrOJSJGQ0FKwvYYF4Q][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],}, reason: zen-disco-receive(join from node[[David Cannon][w2wuzrOJSJGQ0FKwvYYF4Q][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 14:16:27,864][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 746mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:16:27,871][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:16:36,123][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 745.4mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:17:06,094][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 729.1mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:17:36,330][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 728.2mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:17:36,340][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:18:06,132][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 727.8mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:18:36,109][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 726.7mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:19:06,259][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 726.6mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:19:06,264][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:19:36,144][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 726.6mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:20:06,119][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 726.6mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:20:36,130][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 726.2mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:20:36,141][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:21:06,153][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 725.9mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:21:36,254][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 725.7mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:21:36,256][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:22:06,135][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 724.6mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:22:36,157][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 724.5mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:23:06,268][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 724.5mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:23:06,271][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:23:36,680][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 639.4mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:24:06,170][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 639.4mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:24:36,281][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 639.1mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:24:36,285][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:25:06,653][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 639.1mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:25:36,181][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 643.1mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:26:06,287][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 643.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:26:06,290][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:26:36,220][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 643.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:27:06,176][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 643.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:27:36,285][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 643.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:27:36,289][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:28:06,175][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 642.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:28:36,201][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 642.7mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:29:06,222][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:29:06,225][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:29:36,496][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:30:06,213][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:30:36,242][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.8mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:30:36,245][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:31:06,519][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.8mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:31:36,222][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.8mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:32:06,221][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.5mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:32:06,225][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:32:36,364][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.6mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:33:06,684][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.6mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:33:06,687][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:33:36,340][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 636.5mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:34:06,331][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 640.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:34:36,550][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 575.6mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:34:36,553][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:35:06,253][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 570.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:35:36,270][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 565.5mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:36:06,368][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 566.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:36:06,371][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:36:36,354][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 571.5mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:37:06,466][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 568.6mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:37:06,477][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:37:36,876][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 581.1mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:38:06,316][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 576mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:38:36,278][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 575.5mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:38:36,287][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:39:06,283][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 571.8mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:39:36,290][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 571.7mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:39:36,294][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:40:06,301][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 574.4mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:40:36,310][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 552.1mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:40:36,312][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:41:06,517][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 574.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:41:36,321][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 553.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:41:36,336][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:42:06,315][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 555.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:42:36,369][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 555.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:42:36,379][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:43:06,364][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 555.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:43:36,348][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 555.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:44:06,340][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 632.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:44:06,341][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:44:36,348][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 632.1mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:45:06,450][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 632.1mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:45:06,461][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:45:36,364][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 632mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:46:06,353][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 600mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:46:36,364][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 619.4mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:46:36,375][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:47:06,873][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 633.8mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:47:36,427][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 612.7mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:47:36,431][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:48:06,472][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 720.3mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:48:36,378][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 695.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:49:06,443][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 708.8mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:49:06,444][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:49:36,482][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 700.4mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:50:06,481][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 699.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:50:06,489][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:50:36,402][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 703.6mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:51:06,500][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 692.4mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:51:06,511][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:51:36,596][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 714.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:52:06,420][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 714.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:52:36,502][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 718mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:52:36,503][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:53:06,615][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 717.8mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:53:36,801][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 693.7mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:53:36,804][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:54:06,428][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 693.6mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:54:36,571][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 697.3mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:55:07,000][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 691mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:55:07,003][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:55:36,449][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 686.4mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:56:06,626][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 691.5mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:56:36,495][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 689.4mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:56:36,498][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:57:06,452][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 707.9mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:57:36,668][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 700.4mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:57:36,676][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:58:06,476][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 705.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:58:36,656][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 692.5mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:59:06,540][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 691.8mb[0.2%], shards will be relocated away from this node
[2015-10-14 14:59:06,542][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:59:36,481][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 677.3mb[0.2%], shards will be relocated away from this node
[2015-10-14 15:00:06,605][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 576.2mb[0.2%], shards will be relocated away from this node
[2015-10-14 15:00:06,608][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 15:00:36,680][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 958.5mb[0.4%], shards will be relocated away from this node
[2015-10-14 15:01:06,779][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 954.2mb[0.4%], shards will be relocated away from this node
[2015-10-14 15:01:06,790][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 15:01:36,505][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 954.3mb[0.4%], shards will be relocated away from this node
[2015-10-14 15:02:06,650][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 957.5mb[0.4%], shards will be relocated away from this node
[2015-10-14 15:02:36,798][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 959.3mb[0.4%], shards will be relocated away from this node
[2015-10-14 15:02:36,802][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 15:03:06,582][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 941.3mb[0.3%], shards will be relocated away from this node
[2015-10-14 15:03:36,697][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 948.3mb[0.3%], shards will be relocated away from this node
[2015-10-14 15:04:06,521][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 948.2mb[0.3%], shards will be relocated away from this node
[2015-10-14 15:04:06,523][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 15:04:36,540][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 963.6mb[0.4%], shards will be relocated away from this node
[2015-10-14 15:05:06,535][WARN ][cluster.routing.allocation.decider] [Raza] high disk watermark [90%] exceeded on [w2wuzrOJSJGQ0FKwvYYF4Q][David Cannon] free: 953.9mb[0.4%], shards will be relocated away from this node
[2015-10-14 15:05:06,536][INFO ][cluster.routing.allocation.decider] [Raza] high disk watermark exceeded on one or more nodes, rerouting shards

[2015-10-13 18:49:53,877][INFO ][node                     ] [Gee] version[1.7.1], pid[89101], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-13 18:49:53,877][INFO ][node                     ] [Gee] initializing ...
[2015-10-13 18:49:54,052][INFO ][plugins                  ] [Gee] loaded [], sites []
[2015-10-13 18:49:54,135][INFO ][env                      ] [Gee] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [133.4gb], net total_space [232.6gb], types [hfs]
[2015-10-13 18:49:58,374][INFO ][node                     ] [Gee] initialized
[2015-10-13 18:49:58,375][INFO ][node                     ] [Gee] starting ...
[2015-10-13 18:49:58,516][INFO ][transport                ] [Gee] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.145:9300]}
[2015-10-13 18:49:58,550][INFO ][discovery                ] [Gee] elasticsearch/pbarfueRT1yKMg-3ogP1eQ
[2015-10-13 18:50:02,343][INFO ][cluster.service          ] [Gee] new_master [Gee][pbarfueRT1yKMg-3ogP1eQ][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]], reason: zen-disco-join (elected_as_master)
[2015-10-13 18:50:02,366][INFO ][http                     ] [Gee] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.145:9200]}
[2015-10-13 18:50:02,367][INFO ][node                     ] [Gee] started
[2015-10-13 18:50:02,391][INFO ][gateway                  ] [Gee] recovered [0] indices into cluster_state
[2015-10-13 18:51:04,857][INFO ][node                     ] [Gee] stopping ...
[2015-10-13 18:51:04,927][INFO ][node                     ] [Gee] stopped
[2015-10-13 18:51:04,928][INFO ][node                     ] [Gee] closing ...
[2015-10-13 18:51:04,940][INFO ][node                     ] [Gee] closed
[2015-10-13 19:00:36,706][INFO ][node                     ] [Arc] version[1.7.1], pid[89397], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-13 19:00:36,709][INFO ][node                     ] [Arc] initializing ...
[2015-10-13 19:00:36,870][INFO ][plugins                  ] [Arc] loaded [], sites []
[2015-10-13 19:00:36,956][INFO ][env                      ] [Arc] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [133.4gb], net total_space [232.6gb], types [hfs]
[2015-10-13 19:00:41,029][INFO ][node                     ] [Arc] initialized
[2015-10-13 19:00:41,029][INFO ][node                     ] [Arc] starting ...
[2015-10-13 19:00:41,200][INFO ][transport                ] [Arc] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.145:9300]}
[2015-10-13 19:00:41,239][INFO ][discovery                ] [Arc] elasticsearch/HN8u2lrnSrycq6pQAqY3AA
[2015-10-13 19:00:45,035][INFO ][cluster.service          ] [Arc] new_master [Arc][HN8u2lrnSrycq6pQAqY3AA][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]], reason: zen-disco-join (elected_as_master)
[2015-10-13 19:00:45,058][INFO ][http                     ] [Arc] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.145:9200]}
[2015-10-13 19:00:45,058][INFO ][node                     ] [Arc] started
[2015-10-13 19:00:45,069][INFO ][gateway                  ] [Arc] recovered [0] indices into cluster_state
[2015-10-13 19:02:15,825][INFO ][node                     ] [Arc] stopping ...
[2015-10-13 19:02:16,399][INFO ][node                     ] [Arc] stopped
[2015-10-13 19:02:16,402][INFO ][node                     ] [Arc] closing ...
[2015-10-13 19:02:16,758][INFO ][node                     ] [Arc] closed
[2015-10-13 19:17:20,857][INFO ][node                     ] [Raza] version[1.7.1], pid[90335], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-13 19:17:20,859][INFO ][node                     ] [Raza] initializing ...
[2015-10-13 19:17:21,015][INFO ][plugins                  ] [Raza] loaded [], sites []
[2015-10-13 19:17:21,089][INFO ][env                      ] [Raza] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [133.4gb], net total_space [232.6gb], types [hfs]
[2015-10-13 19:17:24,709][INFO ][node                     ] [Raza] initialized
[2015-10-13 19:17:24,709][INFO ][node                     ] [Raza] starting ...
[2015-10-13 19:17:24,907][INFO ][transport                ] [Raza] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.145:9300]}
[2015-10-13 19:17:24,952][INFO ][discovery                ] [Raza] elasticsearch/qCFFzUjQS12EsdxOzv8gig
[2015-10-13 19:17:28,833][INFO ][cluster.service          ] [Raza] new_master [Raza][qCFFzUjQS12EsdxOzv8gig][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]], reason: zen-disco-join (elected_as_master)
[2015-10-13 19:17:28,863][INFO ][http                     ] [Raza] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.145:9200]}
[2015-10-13 19:17:28,863][INFO ][node                     ] [Raza] started
[2015-10-13 19:17:28,871][INFO ][gateway                  ] [Raza] recovered [0] indices into cluster_state
[2015-10-13 19:18:03,141][INFO ][cluster.metadata         ] [Raza] [events] creating index, cause [auto(index api)], templates [], shards [5]/[1], mappings [event]
[2015-10-13 19:18:03,750][INFO ][cluster.metadata         ] [Raza] [events] update_mapping [event] (dynamic)
[2015-10-14 13:56:45,731][INFO ][node                     ] [Alicia Masters] version[1.7.1], pid[22381], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-14 13:56:45,732][INFO ][node                     ] [Alicia Masters] initializing ...
[2015-10-14 13:56:45,909][INFO ][plugins                  ] [Alicia Masters] loaded [], sites []
[2015-10-14 13:56:45,997][INFO ][env                      ] [Alicia Masters] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [784mb], net total_space [232.6gb], types [hfs]
[2015-10-14 13:56:49,768][INFO ][node                     ] [Alicia Masters] initialized
[2015-10-14 13:56:49,768][INFO ][node                     ] [Alicia Masters] starting ...
[2015-10-14 13:56:49,993][INFO ][transport                ] [Alicia Masters] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.126:9300]}
[2015-10-14 13:56:50,058][INFO ][discovery                ] [Alicia Masters] elasticsearch/YN-QYXl5RWu7YGNYoxPE4Q
[2015-10-14 13:56:53,874][INFO ][cluster.service          ] [Alicia Masters] new_master [Alicia Masters][YN-QYXl5RWu7YGNYoxPE4Q][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]], reason: zen-disco-join (elected_as_master)
[2015-10-14 13:56:53,897][INFO ][http                     ] [Alicia Masters] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.126:9200]}
[2015-10-14 13:56:53,897][INFO ][node                     ] [Alicia Masters] started
[2015-10-14 13:56:53,935][INFO ][gateway                  ] [Alicia Masters] recovered [1] indices into cluster_state
[2015-10-14 13:57:23,908][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 784.2mb[0.3%], shards will be relocated away from this node
[2015-10-14 13:57:23,909][INFO ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 13:57:53,890][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 784.1mb[0.3%], shards will be relocated away from this node
[2015-10-14 13:58:23,892][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 783.7mb[0.3%], shards will be relocated away from this node
[2015-10-14 13:58:53,898][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 772.9mb[0.3%], shards will be relocated away from this node
[2015-10-14 13:58:53,899][INFO ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 13:59:23,905][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 740.8mb[0.3%], shards will be relocated away from this node
[2015-10-14 13:59:53,907][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 740.3mb[0.3%], shards will be relocated away from this node
[2015-10-14 13:59:53,907][INFO ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:00:23,910][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 739.7mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:00:53,913][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 739mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:00:53,913][INFO ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:01:23,917][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 739mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:01:53,919][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 738.9mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:01:53,927][INFO ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:02:23,925][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 738.9mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:02:53,928][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 738.9mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:03:23,932][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 738.5mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:03:23,941][INFO ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:03:53,935][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 737.8mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:04:23,940][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 737.8mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:04:53,940][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 737.8mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:04:53,940][INFO ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:05:23,942][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 737.8mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:05:53,945][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 737.8mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:05:53,953][INFO ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-14 14:06:23,951][WARN ][cluster.routing.allocation.decider] [Alicia Masters] high disk watermark [90%] exceeded on [YN-QYXl5RWu7YGNYoxPE4Q][Alicia Masters] free: 737.7mb[0.3%], shards will be relocated away from this node
[2015-10-14 14:16:19,426][INFO ][node                     ] [David Cannon] version[1.7.1], pid[23559], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-14 14:16:19,427][INFO ][node                     ] [David Cannon] initializing ...
[2015-10-14 14:16:19,599][INFO ][plugins                  ] [David Cannon] loaded [], sites []
[2015-10-14 14:16:19,659][INFO ][env                      ] [David Cannon] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [746mb], net total_space [232.6gb], types [hfs]
[2015-10-14 14:16:23,350][INFO ][node                     ] [David Cannon] initialized
[2015-10-14 14:16:23,351][INFO ][node                     ] [David Cannon] starting ...
[2015-10-14 14:16:23,537][INFO ][transport                ] [David Cannon] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.126:9300]}
[2015-10-14 14:16:23,585][INFO ][discovery                ] [David Cannon] elasticsearch/w2wuzrOJSJGQ0FKwvYYF4Q
[2015-10-14 14:16:27,630][INFO ][cluster.service          ] [David Cannon] detected_master [Raza][qCFFzUjQS12EsdxOzv8gig][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]], added {[Raza][qCFFzUjQS12EsdxOzv8gig][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]],}, reason: zen-disco-receive(from master [[Raza][qCFFzUjQS12EsdxOzv8gig][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]]])
[2015-10-14 14:16:27,660][INFO ][http                     ] [David Cannon] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.126:9200]}
<<<<<<< HEAD
[2015-10-14 14:16:27,660][INFO ][node                     ] [David Cannon] started
[2015-10-14 21:37:12,621][INFO ][node                     ] [Kraven the Hunter] version[1.7.1], pid[28614], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-14 21:37:12,623][INFO ][node                     ] [Kraven the Hunter] initializing ...
[2015-10-14 21:37:12,700][INFO ][plugins                  ] [Kraven the Hunter] loaded [], sites []
[2015-10-14 21:37:12,741][INFO ][env                      ] [Kraven the Hunter] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [149gb], net total_space [232.6gb], types [hfs]
[2015-10-14 21:37:14,991][INFO ][node                     ] [Kraven the Hunter] initialized
[2015-10-14 21:37:14,992][INFO ][node                     ] [Kraven the Hunter] starting ...
[2015-10-14 21:37:15,081][INFO ][transport                ] [Kraven the Hunter] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.164:9300]}
[2015-10-14 21:37:15,105][INFO ][discovery                ] [Kraven the Hunter] elasticsearch/SdqJ8RO3Te6hJ5PSXRkRKw
[2015-10-14 21:37:18,558][INFO ][cluster.service          ] [Kraven the Hunter] detected_master [Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]], added {[Danger][ruyQPlLlTum_W-_UpF7a2A][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]],[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 21:37:18,603][INFO ][http                     ] [Kraven the Hunter] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.164:9200]}
[2015-10-14 21:37:18,603][INFO ][node                     ] [Kraven the Hunter] started
[2015-10-14 22:16:25,067][INFO ][discovery.zen            ] [Kraven the Hunter] master_left [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]], reason [do not exists on master, act as master failure]
[2015-10-14 22:16:25,091][WARN ][discovery.zen            ] [Kraven the Hunter] master left (reason = do not exists on master, act as master failure), current nodes: {[Kraven the Hunter][SdqJ8RO3Te6hJ5PSXRkRKw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],[Danger][ruyQPlLlTum_W-_UpF7a2A][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]],}
[2015-10-14 22:16:25,091][INFO ][cluster.service          ] [Kraven the Hunter] removed {[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]],}, reason: zen-disco-master_failed ([Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]])
[2015-10-14 22:16:28,382][WARN ][discovery.zen.ping.multicast] [Kraven the Hunter] received ping response ping_response{node [[Danger][ruyQPlLlTum_W-_UpF7a2A][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]]], id[55], master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [2]
[2015-10-14 22:16:28,383][WARN ][discovery.zen.ping.multicast] [Kraven the Hunter] received ping response ping_response{node [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]], id[19], master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [2]
[2015-10-14 22:16:30,116][INFO ][cluster.service          ] [Kraven the Hunter] detected_master [Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]], added {[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 23:07:50,256][INFO ][discovery.zen            ] [Kraven the Hunter] master_left [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]], reason [do not exists on master, act as master failure]
[2015-10-14 23:07:50,259][WARN ][discovery.zen            ] [Kraven the Hunter] master left (reason = do not exists on master, act as master failure), current nodes: {[Kraven the Hunter][SdqJ8RO3Te6hJ5PSXRkRKw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],[Danger][ruyQPlLlTum_W-_UpF7a2A][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]],}
[2015-10-14 23:07:50,260][INFO ][cluster.service          ] [Kraven the Hunter] removed {[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]],}, reason: zen-disco-master_failed ([Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]])
[2015-10-14 23:07:54,611][WARN ][discovery.zen.ping.multicast] [Kraven the Hunter] received ping response ping_response{node [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]], id[22], master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-10-14 23:07:54,611][WARN ][discovery.zen.ping.multicast] [Kraven the Hunter] received ping response ping_response{node [[Danger][ruyQPlLlTum_W-_UpF7a2A][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]]], id[61], master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-10-14 23:07:55,628][INFO ][cluster.service          ] [Kraven the Hunter] detected_master [Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]], added {[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 23:13:49,878][INFO ][node                     ] [Gaza] version[1.7.1], pid[30003], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-14 23:13:49,878][INFO ][node                     ] [Gaza] initializing ...
[2015-10-14 23:13:49,964][INFO ][plugins                  ] [Gaza] loaded [], sites []
[2015-10-14 23:13:50,012][INFO ][env                      ] [Gaza] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [148.8gb], net total_space [232.6gb], types [hfs]
[2015-10-14 23:13:52,508][INFO ][node                     ] [Gaza] initialized
[2015-10-14 23:13:52,508][INFO ][node                     ] [Gaza] starting ...
[2015-10-14 23:13:52,609][INFO ][transport                ] [Gaza] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.164:9300]}
[2015-10-14 23:13:52,637][INFO ][discovery                ] [Gaza] elasticsearch/3OXKOIagQ72TtKlDtWwhhQ
[2015-10-14 23:13:55,849][INFO ][cluster.service          ] [Gaza] detected_master [Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]], added {[Danger][ruyQPlLlTum_W-_UpF7a2A][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]],[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 23:13:55,889][INFO ][http                     ] [Gaza] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.164:9200]}
[2015-10-14 23:13:55,889][INFO ][node                     ] [Gaza] started
=======
[2015-10-14 14:16:27,660][INFO ][node                     ] [David Cannon] started[2015-10-14 16:21:16,525][INFO ][node                     ] [Shriker] version[1.7.1], pid[6105], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-14 16:21:16,526][INFO ][node                     ] [Shriker] initializing ...
[2015-10-14 16:21:16,683][INFO ][plugins                  ] [Shriker] loaded [], sites []
[2015-10-14 16:21:16,775][INFO ][env                      ] [Shriker] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [133.2gb], net total_space [232.6gb], types [hfs]
[2015-10-14 16:21:21,247][INFO ][node                     ] [Shriker] initialized
[2015-10-14 16:21:21,248][INFO ][node                     ] [Shriker] starting ...
[2015-10-14 16:21:21,611][INFO ][transport                ] [Shriker] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.145:9300]}
[2015-10-14 16:21:21,666][INFO ][discovery                ] [Shriker] elasticsearch/vU_nG2vfSC-sFsZb60bDGQ
[2015-10-14 16:21:25,345][INFO ][cluster.service          ] [Shriker] detected_master [the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]], added {[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]])
[2015-10-14 16:21:25,462][INFO ][gateway.local.state.meta ] [Shriker] [events_development_20151014161811608] dangling index, exists on local file system, but not in cluster metadata, auto import to cluster state [YES]
[2015-10-14 16:21:25,522][INFO ][http                     ] [Shriker] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.145:9200]}
[2015-10-14 16:21:25,529][INFO ][node                     ] [Shriker] started
[2015-10-14 16:34:52,849][INFO ][cluster.service          ] [Shriker] removed {[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],}, reason: zen-disco-receive(from master [[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]])
[2015-10-14 16:34:57,323][INFO ][cluster.service          ] [Shriker] added {[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],}, reason: zen-disco-receive(from master [[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]])
[2015-10-14 16:42:54,892][WARN ][transport.netty          ] [Shriker] exception caught on transport layer [[id: 0x4c6330b1, /192.168.1.145:61173 => /192.168.1.164:9300]], closing connection
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-14 16:42:55,193][INFO ][discovery.zen            ] [Shriker] master_left [[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]], reason [transport disconnected]
[2015-10-14 16:42:55,201][WARN ][discovery.zen            ] [Shriker] master left (reason = transport disconnected), current nodes: {[Shriker][vU_nG2vfSC-sFsZb60bDGQ][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]],[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],}
[2015-10-14 16:42:55,206][INFO ][cluster.service          ] [Shriker] removed {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-master_failed ([the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]])
[2015-10-14 16:43:25,413][WARN ][cluster.service          ] [Shriker] cluster state update task [zen-disco-master_failed ([the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]])] took 30.2s above the warn threshold of 30s
[2015-10-14 16:43:25,414][INFO ][cluster.service          ] [Shriker] detected_master [Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]], reason: zen-disco-receive(from master [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 16:44:46,081][INFO ][cluster.service          ] [Shriker] added {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 16:46:54,774][INFO ][cluster.service          ] [Shriker] removed {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 16:46:54,820][WARN ][action.index             ] [Shriker] failed to perform indices:data/write/index on remote replica [the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]][events][2]
org.elasticsearch.transport.NodeDisconnectedException: [the Renegade Watcher Aron][inet[/192.168.1.164:9300]][indices:data/write/index[r]] disconnected
[2015-10-14 16:49:48,047][INFO ][cluster.service          ] [Shriker] added {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 17:28:16,508][WARN ][transport.netty          ] [Shriker] exception caught on transport layer [[id: 0x25c21fd8, /192.168.1.145:51561 => /192.168.1.164:9300]], closing connection
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-14 17:28:16,508][WARN ][transport.netty          ] [Shriker] exception caught on transport layer [[id: 0x77e16f82, /192.168.1.145:51562 => /192.168.1.164:9300]], closing connection
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-14 17:28:16,508][WARN ][transport.netty          ] [Shriker] exception caught on transport layer [[id: 0xf6d33846, /192.168.1.145:51563 => /192.168.1.164:9300]], closing connection
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-14 17:28:16,508][WARN ][transport.netty          ] [Shriker] exception caught on transport layer [[id: 0xe74286fc, /192.168.1.145:51565 => /192.168.1.164:9300]], closing connection
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-14 17:28:16,508][WARN ][transport.netty          ] [Shriker] exception caught on transport layer [[id: 0x1a9bf759, /192.168.1.145:51564 => /192.168.1.164:9300]], closing connection
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-14 17:28:55,948][INFO ][cluster.service          ] [Shriker] removed {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 17:32:32,940][INFO ][cluster.service          ] [Shriker] added {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 17:49:56,606][INFO ][cluster.service          ] [Shriker] removed {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 18:04:03,062][INFO ][cluster.service          ] [Shriker] added {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 18:34:10,739][INFO ][discovery.zen            ] [Shriker] master_left [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]], reason [transport disconnected]
[2015-10-14 18:34:10,739][INFO ][discovery.zen            ] [Shriker] master_left [[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]], reason [shut_down]
[2015-10-14 18:34:10,793][WARN ][discovery.zen            ] [Shriker] master left (reason = shut_down), current nodes: {[Shriker][vU_nG2vfSC-sFsZb60bDGQ][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]],[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}
[2015-10-14 18:34:10,802][INFO ][cluster.service          ] [Shriker] removed {[Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],}, reason: zen-disco-master_failed ([Hermod][ro7b4KfYTpKXH8UTfKiwIg][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]])
[2015-10-14 18:34:13,974][INFO ][cluster.service          ] [Shriker] detected_master [Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]], added {[Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]],}, reason: zen-disco-receive(from master [[Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 20:53:59,219][INFO ][node                     ] [Danger] version[1.7.1], pid[11265], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-14 20:53:59,220][INFO ][node                     ] [Danger] initializing ...
[2015-10-14 20:53:59,395][INFO ][plugins                  ] [Danger] loaded [], sites []
[2015-10-14 20:53:59,478][INFO ][env                      ] [Danger] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [133.1gb], net total_space [232.6gb], types [hfs]
[2015-10-14 20:54:05,109][INFO ][node                     ] [Danger] initialized
[2015-10-14 20:54:05,122][INFO ][node                     ] [Danger] starting ...
[2015-10-14 20:54:05,503][INFO ][transport                ] [Danger] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.145:9300]}
[2015-10-14 20:54:05,634][INFO ][discovery                ] [Danger] elasticsearch/ruyQPlLlTum_W-_UpF7a2A
[2015-10-14 20:54:08,916][INFO ][cluster.service          ] [Danger] detected_master [Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]], added {[Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]],[Allatou][iO3X70YkRxGcqxwdnKdFxw][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],}, reason: zen-disco-receive(from master [[Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 20:54:08,993][INFO ][http                     ] [Danger] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.145:9200]}
[2015-10-14 20:54:08,994][INFO ][node                     ] [Danger] started
[2015-10-14 20:55:23,270][DEBUG][action.index             ] [Danger] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-10-14 20:55:33,277][DEBUG][action.index             ] [Danger] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-10-14 21:01:18,027][INFO ][cluster.service          ] [Danger] added {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 21:03:22,474][INFO ][discovery.zen            ] [Danger] master_left [[Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]]], reason [shut_down]
[2015-10-14 21:03:22,518][WARN ][discovery.zen            ] [Danger] master left (reason = shut_down), current nodes: {[Danger][ruyQPlLlTum_W-_UpF7a2A][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]],[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],[Allatou][iO3X70YkRxGcqxwdnKdFxw][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],}
[2015-10-14 21:03:22,523][INFO ][cluster.service          ] [Danger] removed {[Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]],}, reason: zen-disco-master_failed ([Torrent][JnXiZrIqQuuyC3kmLYfNaQ][Beepo-Retina.local][inet[/192.168.1.8:9300]])
[2015-10-14 21:03:25,768][INFO ][cluster.service          ] [Danger] detected_master [Allatou][iO3X70YkRxGcqxwdnKdFxw][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]], reason: zen-disco-receive(from master [[Allatou][iO3X70YkRxGcqxwdnKdFxw][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-14 21:24:20,815][DEBUG][action.index             ] [Danger] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-10-14 21:24:30,828][DEBUG][action.index             ] [Danger] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-10-14 21:25:03,767][WARN ][transport.netty          ] [Danger] exception caught on transport layer [[id: 0xc53aca41, /192.168.1.145:63258 => /192.168.1.126:9300]], closing connection
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-14 21:25:03,884][INFO ][discovery.zen            ] [Danger] master_left [[Allatou][iO3X70YkRxGcqxwdnKdFxw][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]], reason [transport disconnected]
[2015-10-14 21:25:03,885][WARN ][discovery.zen            ] [Danger] master left (reason = transport disconnected), current nodes: {[Danger][ruyQPlLlTum_W-_UpF7a2A][Madisons-MacBook-Air.local][inet[/192.168.1.145:9300]],[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}
[2015-10-14 21:25:03,886][INFO ][cluster.service          ] [Danger] removed {[Allatou][iO3X70YkRxGcqxwdnKdFxw][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],}, reason: zen-disco-master_failed ([Allatou][iO3X70YkRxGcqxwdnKdFxw][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]])
[2015-10-14 21:25:07,474][INFO ][cluster.service          ] [Danger] detected_master [Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]], added {[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 21:26:48,984][INFO ][cluster.service          ] [Danger] removed {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 21:27:54,268][INFO ][cluster.service          ] [Danger] added {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 21:32:50,677][INFO ][cluster.service          ] [Danger] removed {[the Renegade Watcher Aron][oBzrVcBuT6KjOrdIJLrAXw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 21:37:19,076][INFO ][cluster.service          ] [Danger] added {[Kraven the Hunter][SdqJ8RO3Te6hJ5PSXRkRKw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 22:13:36,094][INFO ][cluster.service          ] [Danger] removed {[Kraven the Hunter][SdqJ8RO3Te6hJ5PSXRkRKw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 22:16:30,777][INFO ][cluster.service          ] [Danger] added {[Kraven the Hunter][SdqJ8RO3Te6hJ5PSXRkRKw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
[2015-10-14 23:01:36,618][INFO ][cluster.service          ] [Danger] removed {[Kraven the Hunter][SdqJ8RO3Te6hJ5PSXRkRKw][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(from master [[Vindaloo][if7uzR_tRZi6vnJyi8EU0w][Beepo-Retina.local][inet[/192.168.1.8:9300]]])
>>>>>>> developer
[2015-10-15 14:14:49,760][INFO ][node                     ] [Patriot] version[1.7.1], pid[20492], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-15 14:14:49,760][INFO ][node                     ] [Patriot] initializing ...
[2015-10-15 14:14:49,887][INFO ][plugins                  ] [Patriot] loaded [], sites []
[2015-10-15 14:14:49,944][INFO ][env                      ] [Patriot] using [1] data paths, mounts [[/ (/dev/disk0s2)]], net usable_space [26.1gb], net total_space [352.9gb], types [hfs]
[2015-10-15 14:14:52,664][INFO ][node                     ] [Patriot] initialized
[2015-10-15 14:14:52,665][INFO ][node                     ] [Patriot] starting ...
[2015-10-15 14:14:52,761][INFO ][transport                ] [Patriot] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.8:9300]}
[2015-10-15 14:14:52,786][INFO ][discovery                ] [Patriot] elasticsearch/VTJ3zgtBSqmGpvshyOEPhQ
[2015-10-15 14:14:56,574][INFO ][cluster.service          ] [Patriot] new_master [Patriot][VTJ3zgtBSqmGpvshyOEPhQ][Beepo-Retina.local][inet[/192.168.1.8:9300]], reason: zen-disco-join (elected_as_master)
[2015-10-15 14:14:56,599][INFO ][http                     ] [Patriot] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.8:9200]}
[2015-10-15 14:14:56,599][INFO ][node                     ] [Patriot] started
[2015-10-15 14:14:56,634][INFO ][gateway                  ] [Patriot] recovered [2] indices into cluster_state
[2015-10-15 14:15:26,588][WARN ][cluster.routing.allocation.decider] [Patriot] high disk watermark [90%] exceeded on [VTJ3zgtBSqmGpvshyOEPhQ][Patriot] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:15:26,588][INFO ][cluster.routing.allocation.decider] [Patriot] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:15:56,584][WARN ][cluster.routing.allocation.decider] [Patriot] high disk watermark [90%] exceeded on [VTJ3zgtBSqmGpvshyOEPhQ][Patriot] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:16:26,581][WARN ][cluster.routing.allocation.decider] [Patriot] high disk watermark [90%] exceeded on [VTJ3zgtBSqmGpvshyOEPhQ][Patriot] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:16:56,589][WARN ][cluster.routing.allocation.decider] [Patriot] high disk watermark [90%] exceeded on [VTJ3zgtBSqmGpvshyOEPhQ][Patriot] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:16:56,589][INFO ][cluster.routing.allocation.decider] [Patriot] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:17:26,586][WARN ][cluster.routing.allocation.decider] [Patriot] high disk watermark [90%] exceeded on [VTJ3zgtBSqmGpvshyOEPhQ][Patriot] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:17:56,588][WARN ][cluster.routing.allocation.decider] [Patriot] high disk watermark [90%] exceeded on [VTJ3zgtBSqmGpvshyOEPhQ][Patriot] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:17:56,588][INFO ][cluster.routing.allocation.decider] [Patriot] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:18:26,592][WARN ][cluster.routing.allocation.decider] [Patriot] high disk watermark [90%] exceeded on [VTJ3zgtBSqmGpvshyOEPhQ][Patriot] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:18:56,592][WARN ][cluster.routing.allocation.decider] [Patriot] high disk watermark [90%] exceeded on [VTJ3zgtBSqmGpvshyOEPhQ][Patriot] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:18:56,592][INFO ][cluster.routing.allocation.decider] [Patriot] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:19:16,803][INFO ][node                     ] [Patriot] stopping ...
[2015-10-15 14:19:16,845][INFO ][node                     ] [Patriot] stopped
[2015-10-15 14:19:16,846][INFO ][node                     ] [Patriot] closing ...
[2015-10-15 14:19:16,851][INFO ][node                     ] [Patriot] closed
>>>>>>> developer
[2015-10-15 14:32:45,072][INFO ][node                     ] [Doctor Doom] version[1.7.1], pid[22510], build[b88f43f/2015-07-29T09:54:16Z]
[2015-10-15 14:32:45,072][INFO ][node                     ] [Doctor Doom] initializing ...
[2015-10-15 14:32:45,141][INFO ][plugins                  ] [Doctor Doom] loaded [], sites []
[2015-10-15 14:32:45,179][INFO ][env                      ] [Doctor Doom] using [1] data paths, mounts [[/ (/dev/disk0s2)]], net usable_space [26.1gb], net total_space [352.9gb], types [hfs]
[2015-10-15 14:32:47,191][INFO ][node                     ] [Doctor Doom] initialized
[2015-10-15 14:32:47,191][INFO ][node                     ] [Doctor Doom] starting ...
[2015-10-15 14:32:47,256][INFO ][transport                ] [Doctor Doom] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/192.168.1.8:9300]}
[2015-10-15 14:32:47,272][INFO ][discovery                ] [Doctor Doom] elasticsearch/1ulySXLlQnKtQTyYaJsMAA
[2015-10-15 14:32:51,048][INFO ][cluster.service          ] [Doctor Doom] new_master [Doctor Doom][1ulySXLlQnKtQTyYaJsMAA][Beepo-Retina.local][inet[/192.168.1.8:9300]], reason: zen-disco-join (elected_as_master)
[2015-10-15 14:32:51,083][INFO ][http                     ] [Doctor Doom] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/192.168.1.8:9200]}
[2015-10-15 14:32:51,083][INFO ][node                     ] [Doctor Doom] started
[2015-10-15 14:32:51,106][INFO ][gateway                  ] [Doctor Doom] recovered [2] indices into cluster_state
[2015-10-15 14:33:21,061][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:33:21,061][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:33:51,056][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:33:59,790][INFO ][cluster.metadata         ] [Doctor Doom] [events_development_20151014220818574] update_mapping [event] (dynamic)
[2015-10-15 14:34:21,057][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:34:51,057][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:34:51,057][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:35:21,058][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:35:51,057][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:35:51,057][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:36:06,319][INFO ][cluster.service          ] [Doctor Doom] added {[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(join from node[[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]])
[2015-10-15 14:36:06,371][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:36:21,061][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:36:51,061][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:36:51,061][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:37:21,213][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:37:51,360][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:37:51,361][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:38:21,111][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:38:51,089][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:39:21,144][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:39:21,145][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:39:51,244][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:40:21,070][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:40:51,145][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:40:51,146][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:41:21,072][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:41:51,548][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:41:51,548][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:42:21,153][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.8gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:42:51,084][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:43:21,186][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:43:21,186][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:43:51,120][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:44:21,501][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:44:21,502][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:44:51,195][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:45:21,298][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:45:51,096][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:45:51,097][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:46:21,214][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:46:51,309][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:46:51,309][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:47:21,091][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:47:51,111][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:48:21,109][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:48:21,109][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:49:06,091][DEBUG][action.admin.cluster.node.stats] [Doctor Doom] failed to execute on node [By6iy8QiQG2RvXe_GP6aaA]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [Captain Britain][inet[/192.168.1.164:9300]][cluster:monitor/nodes/stats[n]] request_id [1348] timed out after [15005ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:529)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-15 14:49:21,090][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:49:36,090][DEBUG][action.admin.cluster.node.stats] [Doctor Doom] failed to execute on node [By6iy8QiQG2RvXe_GP6aaA]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [Captain Britain][inet[/192.168.1.164:9300]][cluster:monitor/nodes/stats[n]] request_id [1360] timed out after [15002ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:529)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-15 14:49:37,905][WARN ][transport.netty          ] [Doctor Doom] exception caught on transport layer [[id: 0xad69d8f6, /192.168.1.8:54319 => /192.168.1.164:9300]], closing connection
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-15 14:49:37,909][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][0], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,909][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][2], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,910][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,910][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,909][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,909][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,909][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][0], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,911][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,911][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,911][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,911][INFO ][cluster.service          ] [Doctor Doom] removed {[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-node_failed([Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]), reason transport disconnected
[2015-10-15 14:49:37,911][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,911][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][2], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,911][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][2], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,911][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,910][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][0], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,910][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,910][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][0], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@31a82043]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,910][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,910][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,910][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][2], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52d36421]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 14:49:37,918][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [8] unassigned shards, next check in [59.9s]
[2015-10-15 14:49:37,922][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 14:49:37,923][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:49:51,093][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:50:21,092][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:50:51,094][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:50:51,094][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:51:21,098][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:51:51,098][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:51:51,098][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:52:21,102][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:52:51,105][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:52:51,105][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:53:21,107][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:53:51,108][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:53:51,108][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:54:21,112][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:54:51,113][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:54:51,113][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:55:21,112][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:55:51,113][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:55:51,113][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:56:21,113][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:56:37,436][INFO ][cluster.service          ] [Doctor Doom] added {[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(join from node[[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]])
[2015-10-15 14:56:37,475][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [0] unassigned shards, next check in [0s]
[2015-10-15 14:56:37,484][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:56:51,118][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:56:51,118][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:56:51,302][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [0] unassigned shards, next check in [0s]
[2015-10-15 14:56:51,419][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [0] unassigned shards, next check in [0s]
[2015-10-15 14:56:51,814][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [0] unassigned shards, next check in [0s]
[2015-10-15 14:56:52,053][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [0] unassigned shards, next check in [0s]
[2015-10-15 14:56:52,580][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [0] unassigned shards, next check in [0s]
[2015-10-15 14:56:52,687][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [0] unassigned shards, next check in [0s]
[2015-10-15 14:56:52,725][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [0] unassigned shards, next check in [0s]
[2015-10-15 14:57:21,192][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:57:51,281][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:57:51,281][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:58:21,427][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:58:51,195][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:59:21,305][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 14:59:21,305][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 14:59:51,568][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:00:21,147][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:00:51,130][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:00:51,130][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:01:21,234][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:01:51,190][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:01:51,190][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:02:21,139][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:02:51,408][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:02:51,408][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:03:21,211][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:03:33,076][INFO ][cluster.service          ] [Doctor Doom] added {[G-Force][WXpxV3arQ7KsT6nURFe7ig][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]],}, reason: zen-disco-receive(join from node[[G-Force][WXpxV3arQ7KsT6nURFe7ig][Nruthyas-MacBook-Air.local][inet[/192.168.1.126:9300]]])
[2015-10-15 15:03:33,223][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.4gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:03:33,223][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 25.9gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:03:51,151][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.4gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:03:51,151][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:04:21,478][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:04:21,478][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:04:21,478][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:04:51,230][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:04:51,230][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:05:21,156][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:05:21,156][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:05:51,458][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:05:51,458][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:05:51,458][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:06:21,232][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:06:21,232][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:06:51,318][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:06:51,318][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:07:21,616][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:07:21,616][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:07:21,616][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:07:51,220][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:07:51,220][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:08:21,355][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:08:21,355][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:08:51,168][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:08:51,169][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:08:51,169][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:09:21,266][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:09:21,267][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:09:51,363][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:09:51,363][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:09:51,363][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:10:21,203][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:10:21,203][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:10:51,274][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:10:51,274][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:11:21,178][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:11:21,178][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:11:21,178][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:11:51,373][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:11:51,373][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:12:21,277][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:12:21,278][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:12:21,278][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:12:51,176][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:12:51,176][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:13:21,460][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:13:21,460][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:13:21,460][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:13:51,286][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:13:51,287][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:14:21,567][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:14:21,567][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:14:21,567][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:14:51,188][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:14:51,188][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:15:21,191][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:15:21,192][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:16:06,178][DEBUG][action.admin.cluster.node.stats] [Doctor Doom] failed to execute on node [By6iy8QiQG2RvXe_GP6aaA]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [Captain Britain][inet[/192.168.1.164:9300]][cluster:monitor/nodes/stats[n]] request_id [4066] timed out after [15005ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:529)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-15 15:16:21,178][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:16:21,178][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:16:21,178][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:16:36,176][DEBUG][action.admin.cluster.node.stats] [Doctor Doom] failed to execute on node [By6iy8QiQG2RvXe_GP6aaA]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [Captain Britain][inet[/192.168.1.164:9300]][cluster:monitor/nodes/stats[n]] request_id [4108] timed out after [15004ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:529)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-15 15:16:51,179][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:16:51,179][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:16:51,179][WARN ][discovery.zen.publish    ] [Doctor Doom] timed out waiting for all nodes to process published state [74] (timeout [30s], pending nodes: [[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]])
[2015-10-15 15:16:51,180][WARN ][cluster.service          ] [Doctor Doom] cluster state update task [cluster_reroute (api)] took 30s above the warn threshold of 30s
[2015-10-15 15:17:02,344][WARN ][transport                ] [Doctor Doom] Received response for a request that has timed out, sent [41172ms] ago, timed out [26168ms] ago, action [cluster:monitor/nodes/stats[n]], node [[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]], id [4108]
[2015-10-15 15:17:04,884][INFO ][cluster.service          ] [Doctor Doom] removed {[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-node_failed([Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]), reason failed to ping, tried [3] times, each with maximum [30s] timeout
[2015-10-15 15:17:05,191][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [8] unassigned shards, next check in [59.6s]
[2015-10-15 15:17:05,199][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][0], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5c3d5718]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,199][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5c3d5718]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,199][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@809c62d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,199][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][0], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5c3d5718]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,200][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5c3d5718]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,199][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5c3d5718]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,199][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][2], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5c3d5718]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,199][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5c3d5718]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,200][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@2f1ad5d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,200][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@2f1ad5d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,200][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@2f1ad5d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,202][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@809c62d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,200][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@2f1ad5d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,200][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][2], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@2f1ad5d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,200][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][0], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@2f1ad5d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,200][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@2f1ad5d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,202][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][2], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@809c62d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,202][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][2], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@809c62d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,201][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][0], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@809c62d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,201][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@809c62d]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:17:05,201][DEBUG][action.admin.cluster.node.stats] [Doctor Doom] failed to execute on node [By6iy8QiQG2RvXe_GP6aaA]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][cluster:monitor/nodes/stats[n]] disconnected
[2015-10-15 15:17:05,204][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:17:05,204][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:17:08,838][INFO ][cluster.service          ] [Doctor Doom] added {[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(join from node[[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]])
[2015-10-15 15:17:08,884][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:17:08,884][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:17:21,480][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:17:21,480][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:17:21,480][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:17:51,202][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:17:51,202][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:18:21,462][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:18:21,462][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:18:51,210][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:18:51,210][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:18:51,210][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:19:21,498][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:19:21,498][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:19:51,325][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:19:51,325][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:19:51,325][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:20:21,713][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:20:21,713][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:20:51,224][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:20:51,225][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:21:21,319][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:21:21,319][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:21:21,319][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:21:51,220][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:21:51,221][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:22:21,234][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:22:21,234][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:22:51,430][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:22:51,430][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:22:51,430][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:23:21,484][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:23:21,484][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:23:51,240][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:23:51,240][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:24:21,279][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:24:21,279][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:24:21,279][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:24:51,397][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:24:51,397][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:25:21,236][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:25:21,236][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:25:51,361][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:25:51,361][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:25:51,361][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:26:21,529][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:26:21,529][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:26:51,261][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:26:51,261][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:27:21,803][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:27:21,803][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:27:21,803][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:27:51,288][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:27:51,288][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:28:21,270][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:28:21,270][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:28:51,659][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:28:51,660][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:28:51,660][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:29:21,251][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:29:21,251][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:29:51,408][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:29:51,408][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:30:21,507][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:30:21,507][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:30:21,507][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:30:51,266][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:30:51,266][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:31:21,417][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:31:21,417][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:31:51,416][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:31:51,416][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:31:51,416][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:32:21,319][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:32:21,319][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:32:51,426][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:32:51,426][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:32:51,427][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:33:21,277][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:33:21,277][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:33:51,328][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:33:51,328][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:34:21,434][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:34:21,434][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:34:21,434][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:34:51,674][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:34:51,674][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:35:21,979][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:35:21,979][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:35:21,979][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:35:51,342][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:35:51,342][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:36:21,444][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:36:21,444][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:36:51,286][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:36:51,286][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:36:51,286][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:37:21,361][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:37:21,361][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:38:06,287][DEBUG][action.admin.cluster.node.stats] [Doctor Doom] failed to execute on node [By6iy8QiQG2RvXe_GP6aaA]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [Captain Britain][inet[/192.168.1.164:9300]][cluster:monitor/nodes/stats[n]] request_id [7259] timed out after [15003ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:529)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-15 15:38:21,287][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:38:21,287][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:38:21,287][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:38:36,285][DEBUG][action.admin.cluster.node.stats] [Doctor Doom] failed to execute on node [By6iy8QiQG2RvXe_GP6aaA]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [Captain Britain][inet[/192.168.1.164:9300]][cluster:monitor/nodes/stats[n]] request_id [7301] timed out after [14999ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:529)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-15 15:38:51,287][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:38:51,288][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:38:51,288][WARN ][discovery.zen.publish    ] [Doctor Doom] timed out waiting for all nodes to process published state [105] (timeout [30s], pending nodes: [[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]])
[2015-10-15 15:38:51,290][WARN ][cluster.service          ] [Doctor Doom] cluster state update task [cluster_reroute (api)] took 30s above the warn threshold of 30s
[2015-10-15 15:38:56,547][WARN ][transport.netty          ] [Doctor Doom] exception caught on transport layer [[id: 0x3733be92, /192.168.1.8:55612 => /192.168.1.164:9300]], closing connection
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2015-10-15 15:38:56,549][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][0], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,549][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][0], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,549][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][2], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,549][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][2], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,549][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,550][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,550][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,549][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,551][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,549][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,549][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,549][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@568e034b]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,552][DEBUG][action.admin.cluster.node.stats] [Doctor Doom] failed to execute on node [By6iy8QiQG2RvXe_GP6aaA]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][cluster:monitor/nodes/stats[n]] disconnected
[2015-10-15 15:38:56,551][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,553][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][2], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,553][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,551][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,551][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,551][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][2], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,551][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][2], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,550][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][0], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,550][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,550][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][0], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1974edd1]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,554][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][2], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,554][INFO ][cluster.service          ] [Doctor Doom] removed {[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-node_failed([Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]), reason transport disconnected
[2015-10-15 15:38:56,554][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,554][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][4], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,553][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][3], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,553][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,553][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][1], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,553][DEBUG][action.admin.indices.stats] [Doctor Doom] [events_development_20151014220818574][0], node[By6iy8QiQG2RvXe_GP6aaA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,553][DEBUG][action.admin.indices.stats] [Doctor Doom] [events][0], node[By6iy8QiQG2RvXe_GP6aaA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@35199d7]
org.elasticsearch.transport.NodeDisconnectedException: [Captain Britain][inet[/192.168.1.164:9300]][indices:monitor/stats[s]] disconnected
[2015-10-15 15:38:56,562][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:38:56,562][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:38:56,571][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [8] unassigned shards, next check in [59.9s]
[2015-10-15 15:39:21,650][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:39:21,650][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:39:21,650][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:39:51,834][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:39:51,834][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:40:22,551][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:40:22,551][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:40:22,551][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:40:51,300][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:40:51,300][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:41:21,583][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:41:21,583][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:41:51,340][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:41:51,340][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:41:51,340][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:42:21,302][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:42:21,302][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:42:51,306][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:42:51,306][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:43:21,390][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:43:21,390][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:43:21,390][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:43:51,534][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:43:51,534][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.3%], shards will be relocated away from this node
[2015-10-15 15:44:21,308][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:44:21,309][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:44:51,311][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:44:51,311][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:44:51,312][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:45:21,313][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:45:21,314][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:45:51,694][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:45:51,694][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:45:51,694][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:46:21,409][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:46:21,409][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:46:51,320][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:46:51,320][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:47:21,873][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:47:21,873][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:47:21,873][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:47:51,324][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:47:51,324][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:48:21,325][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:48:21,325][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:48:51,357][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:48:51,357][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.1gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:48:51,357][INFO ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark exceeded on one or more nodes, rerouting shards
[2015-10-15 15:49:21,425][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:49:21,425][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
[2015-10-15 15:49:30,525][INFO ][cluster.service          ] [Doctor Doom] added {[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]],}, reason: zen-disco-receive(join from node[[Captain Britain][By6iy8QiQG2RvXe_GP6aaA][Joies-MacBook-Pro.local][inet[/192.168.1.164:9300]]])
[2015-10-15 15:49:30,546][INFO ][cluster.routing          ] [Doctor Doom] delaying allocation for [0] unassigned shards, next check in [0s]
[2015-10-15 15:49:30,552][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [WXpxV3arQ7KsT6nURFe7ig][G-Force] free: 3.3gb[1.4%], shards will be relocated away from this node
[2015-10-15 15:49:30,552][WARN ][cluster.routing.allocation.decider] [Doctor Doom] high disk watermark [90%] exceeded on [1ulySXLlQnKtQTyYaJsMAA][Doctor Doom] free: 26.2gb[7.4%], shards will be relocated away from this node
